{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:33:10.854946Z",
     "start_time": "2024-05-19T15:33:09.152227Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "10b19e6025b8c5d2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sources and Citations\n",
    "\n",
    "Fisman, R. J., Iyengar, S. S, Kamenica, E. & Simonson, I. (2006). *Gender Differences in Mate Selection: Evidence from a Speed Dating Experiment*. [http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating]. The Quarterly Journal of Economics. https://academiccommons.columbia.edu/doi/10.7916/D8FB585Z\n",
    "\n",
    "Short post and supplemental information about the dataset and the associated experiment: [https://statmodeling.stat.columbia.edu/2008/01/21/the_speeddating_1](https://statmodeling.stat.columbia.edu/2008/01/21/the_speeddating_1). \n",
    "\n",
    "The link for the file share in the formal citation at the start of this cell has both the data in CSV format and a key for understanding the CSV: [http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating](http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating)\n",
    "\n",
    "Dataset that I originally found and that led me to the source at the Columbia site: [https://www.openml.org/search?type=data&sort=runs&status=active&id=40536](https://www.openml.org/search?type=data&sort=runs&status=active&id=40536)"
   ],
   "id": "bf0a1369558ebc74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data and Research Paper Summary \n",
    "\n",
    "This dataset comes from an experiment by Raymond Fisman and Sheena Iyengar of the Columbia Business School about participants in a speed dating experiment. I found an open copy of the data hosted on a Columbia University file share from a well-known statistics professor at Columbia.\n",
    "\n",
    "The researchers conducted a series of separate speed date events where they rotated participants through four-minute speed dates and asked participants to rate their partners after each date. The ratings are based around five attributes:\n",
    "\n",
    "- Attractive\n",
    "- Sincere\n",
    "- Intelligent\n",
    "- Fun\n",
    "- Ambitious\n",
    "- Shared interests\n",
    "\n",
    "The researchers end up using attractiveness, intelligence, and ambition while dropping the remaining three attributes. Participants are also asked to fill out pre-event surveys to provide non-event data that is also used to determine degrees of similarity between participants. \n",
    "\n",
    "Part of the large feature space in the CSV is due to the combinations of attribute ratings across different partners, averages about individuals based on ratings by all of their partners, and other ways of combining the event survey and pre-event survey results.\n",
    "\n",
    "The researchers focus on differential gender preferences about these attributes, trying to glean ways in which women and men value different characteristics during these dates. \n",
    "\n",
    "It is important to note a couple of potential issues with the experiment design. The participants were students in Columbia University graduate and professional programs, and the dates are heteronormative. These both restrict the generalizability of the findings. I am also curious about the justification of using speed dating as a stand-in for all dating since speed dating seems to me to be a very different experience from dating over a longer time scale.\n",
    "\n",
    "The data explores how different demographics and personal characteristics affect participants' feelings about the speed dates they participate in. One target variable is the `match` column that indicates if both participants in the speed date want to meet again, but the experimental design allows for decisions that are more granular than match or no match, and the associated paper focuses on the `dec` column that has yes and no decisions by individuals about each date instead of matches that have yes decisions on both sides. The researchers use the `dec` values to determine what women and men value in partners, honing in on differences in what women and men prioritize.\n",
    "\n",
    "The paper also references different social theories and starts to explore larger meanings about men and women based on this research's findings, including starting to challenge some of their own findings."
   ],
   "id": "31f471e141b1a706"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Project\n",
    "\n",
    "The choice of marriage partner is a perennial question. The more successful relationships out there, the better. On a personal note, I am looking at starting dating again myself, so I am curious about research that can help me to understand my own preferences and how those may fit in with dates that I go on. \n",
    "\n",
    "Because of the size of the feature space, layers of complexity, social theory, and prior knowledge built into the approach in the paper, I am going to attempt something simpler: can I predict if I will want a second date with someone and/or evaluate what factors are more important in terms of determining if I want a second date?\n",
    "\n",
    "This is a classification problem that will use different features to predict if I will make a yes or no decision to see a person again at the end of the date. After training the model, I will provide most of the inputs before going on a date. Only one set of features will come from my experience on the date. This reduces the complexity of the model by quite a lot, but it keeps me from having to gather information from others in order to use the model, a simplification that I want to lean into for the first iteration, though this admittedly cuts out important information from the other person on the date that would help refine the model further and be more honest in terms of capturing both people's opinions about the date and about each other.\n",
    "\n",
    "A next step of this analysis would be to begin to look at features leading to matches -- situations where both date participants say yes to a second date -- but I would rather break the progression to that up into steps."
   ],
   "id": "81b2aeb68c1ecb50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fixing Bad Characters in Source CSV\n",
    "\n",
    "The source CSV from the link above has some characters that got encoded with the Unicode replacement character, the diamond with a question mark in it. You can search for this by using a regex and looking for code `\\uFFFD` or `\\xEF\\xBF\\xBD`. These replacement characters look like the only non-ASCII characters. You can search for non-ASCII characters with the character set `[^\\x00-\\x7F]`. A visual scan of the bad rows looks like the characters are meant to be 'é'.\n",
    "\n",
    "Sample bad value in the `undergra` field from the source CSV: Ecole Normale Sup�rieure, Paris\n",
    "\n",
    "\n",
    "The following code block calls out to the shell to create a copy of the speed dating CSV and then run `sed` to replace the replacement characters with regular 'e's to keep everything in ASCII. I decided to use shell commands because I had trouble finding a way to read the bad characters in with Python, so I could not get to the step of replacing them in Python. I was able to manually change them with find and replace in Vim, so I modified that for `sed` for the solution below.\n",
    "\n",
    "I ran this on MacOS. You may need to make some tweaks for Windows in particular."
   ],
   "id": "ff276e635ece96ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:33:11.203225Z",
     "start_time": "2024-05-19T15:33:10.857078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "! cp ./data/Speed\\ Dating\\ Data.csv ./data/speed_dating_data_fixed.csv\n",
    "! sed -i '' 's/\\xEF\\xBF\\xBD/e/g' ./data/speed_dating_data_fixed.csv  "
   ],
   "id": "38ce16dd610a88d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading and Initial Exploration",
   "id": "f50dd43b59522039"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:33:11.484385Z",
     "start_time": "2024-05-19T15:33:11.205634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The low_memory=False param tells pandas to determine column data types by looking at all rows\n",
    "# in each column, resulting in needing to read in the entire CSV before being able to determine\n",
    "# data types. low_memory=True results in chunking when reading in the file, and each chunk can\n",
    "# infer a different data type.\n",
    "\n",
    "df_raw = pd.read_csv('./data/speed_dating_data_fixed.csv', low_memory=False)\n",
    "df_raw.head(10)"
   ],
   "id": "fffe6b33320eb605",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave round position  positin1  order  ...  \\\n",
       "0  1.0  1.0     0.0    1       1     1    10        7       NaN      4  ...   \n",
       "1  1.0  1.0     0.0    1       1     1    10        7       NaN      3  ...   \n",
       "2  1.0  1.0     0.0    1       1     1    10        7       NaN     10  ...   \n",
       "3  1.0  1.0     0.0    1       1     1    10        7       NaN      5  ...   \n",
       "4  1.0  1.0     0.0    1       1     1    10        7       NaN      7  ...   \n",
       "5  1.0  1.0     0.0    1       1     1    10        7       NaN      6  ...   \n",
       "6  1.0  1.0     0.0    1       1     1    10        7       NaN      1  ...   \n",
       "7  1.0  1.0     0.0    1       1     1    10        7       NaN      2  ...   \n",
       "8  1.0  1.0     0.0    1       1     1    10        7       NaN      8  ...   \n",
       "9  1.0  1.0     0.0    1       1     1    10        7       NaN      9  ...   \n",
       "\n",
       "   attr3_3  sinc3_3 intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
       "0      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "1      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "2      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "3      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "4      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "5      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "6      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "7      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "8      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "9      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "\n",
       "   fun5_3  amb5_3  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  \n",
       "5     NaN     NaN  \n",
       "6     NaN     NaN  \n",
       "7     NaN     NaN  \n",
       "8     NaN     NaN  \n",
       "9     NaN     NaN  \n",
       "\n",
       "[10 rows x 195 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 195 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:33:11.491229Z",
     "start_time": "2024-05-19T15:33:11.487280Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'The dataset has {df_raw.shape[0]:,} rows and {df_raw.shape[1]} columns')",
   "id": "c72a723257d77333",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 8,379 rows and 195 columns\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Column Summary\n",
    "\n",
    "One of the more difficult aspects of this project is understanding and deciding what to do with the feature space of 195 columns. There are features with answers to the same questions asked at different times. There are features with speculative responses by participants. There are features with self-reported answers about questions such as what attributes someone likes in a partner, what someone thinks others find important in partners, and what others think about themselves. There are different approaches to ratings between different groups of participants. These and other particulars make the preprocessing for this dataset a bit trickier than expected. That said, because of the range of data available, the dataset does offer itself up to a range of questions.\n",
    "\n",
    "One clarifying point for terminology. I use \"participant\" to refer to the individual that a row is for, \"partner\" for the other person participating in the date with the participant in that row, and \"participants\" (plural) to refer to more than one row or rows in general.\n",
    "\n",
    "The details for these columns come from the \"Speed Dating Data Key.doc\" data dictionary reference document. \n",
    "\n",
    "Here is a general summary of the features:\n",
    "\n",
    "There is a group of 28 questions that show up 4 times. Combined, these account for about 57% of the total columns. There is an interesting research question looking at what participants change during each of these repetitions, but I will go a different route and will not need to use all of these repetitions for my analysis.\n",
    "\n",
    "These 28 repeating questions are related to these six attributes:\n",
    "\n",
    "- Attractive\n",
    "- Sincere\n",
    "- Intelligent\n",
    "- Fun\n",
    "- Ambitious\n",
    "- Shared interests (sometimes shared interests is not included)\n",
    "\n",
    "This block of questions for each row asks that participant how they value these attributes, how they think fellow men or women value these attributes, how they think the opposite sex rates the importance of each of these attributes in potential partners, how participants rate themselves on these attributes, and how participants think others rate them on each of these attributes.\n",
    "\n",
    "Note how within this repeating block of questions there are features that come from ratings that participants give themselves, that they predict about others, that they give to date partners, and that they receive from date partners. There is another interesting research question here about how participants may change their answers between repetitions, and there is another question looking at how self-ratings line up with ratings from date partners. I will not go into either of those directions with my analysis, but they would be interesting to look at.\n",
    "\n",
    "Outside of the repeating block of features, there are a couple of other feature groupings that can help in understanding the feature space.\n",
    "\n",
    "Intro info for a particular speed date:\n",
    "- Different types of identifiers with different groupings\n",
    "- Metadata about the event and date at event\n",
    "- Boolean flag for match or no match\n",
    "- Correlation between both participants' ratings of interest\n",
    "- Boolean flag for same race\n",
    "- Info about or from partner for that date, including preferences, decision about meeting again, and ratings of individual for that row\n",
    "\n",
    "Signup/Time1 -- survey filled out by students interested in participating in speed dating event:\n",
    "- Demographic and other personal info about survey applicant\n",
    "- Ratings interest in different activities\n",
    "- Expectations for the dating event\n",
    "- First time answering the repeating block of questions\n",
    "\n",
    "Scorecard -- filled out by participants after each date:\n",
    "- Rate date partner on the six attributes\n",
    "- Decision about wanting to meet that partner again\n",
    "- Overall rating on partner and if you think they will say yes to wanting to see you again\n",
    "\n",
    "Halfway point of speed dating event:\n",
    "- Answer the repeating block of questions again\n",
    "\n",
    "Followup/Time2 -- filled out the day after participating in an event:\n",
    "- Feedback on the event\n",
    "- Answer the repeating block of questions again\n",
    "\n",
    "Followup2/Time3 -- 3-4 weeks after being sent matches:\n",
    "- Feedback related to participants' matches\n",
    "- Answer the repeating block of questions again"
   ],
   "id": "a54ff011b0dd7eb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What to Do With All These Features\n",
    "\n",
    "Next is to narrow the feature space down to what we will use for modeling. Note that the only categorical variable that will need encoding is `goal`. I am treating the 1-10 ratings as discrete numeric variables instead of as ordinal categorical variables since the current numeric encoding captures the order that we want for them.\n",
    "\n",
    "Here are the features that we will keep:\n",
    "- gender (boolean): indicates if participant is male or female\n",
    "- int_corr (continuous & in range [-1, 1]): correlation between ratings of interests between date participants; this summarizes down participants' interest ratings for a group of 17 activities\n",
    "- age_o (continuous & in range [18,55]): partner's age\n",
    "- age (continuous & in range [18,55]): participant's age\n",
    "- goal (categorical): participant's primary goal in participating in event\n",
    "    1. Seemed like a fun night out\n",
    "    2. To meet new people\n",
    "    3. To get a date\n",
    "    4. Looking for a serious relationship\n",
    "    5. To say I did it\n",
    "    6. Other\n",
    "- exphappy (discrete & in range [1,10]): how happy participant expects to be with people they meet at event\n",
    "\n",
    "From here onwards, we encounter repetitions of the six attributes above. I will provide headers that explain what the repetitions are asking about instead of adding that as a description for each feature.\n",
    "\n",
    "Here are the abbreviations:\n",
    "\n",
    "- attr#_#: attractive\n",
    "- sinc#_#: sincere\n",
    "- intel#_#: intelligent\n",
    "- fun#_#: fun\n",
    "- amb#_#: ambitious\n",
    "- shar#_#: shared interests\n",
    "\n",
    "The data dictionary says that waves 6-9 rate some groups of these features on a 1-10 scale while the remaining waves distribute 100 points across all five or six features. Some feature groupings that the dictionary indicates should be [1,10] are already rescaled to [0,100] such that the total of all of the features in the grouping for each row sum to 100, so the standardization turned [1,10] ratings into relative ratings on a [1,100] percentage scale. For groupings that require further standardization, we will do the same by summing the total for the grouping for a row and standardize it if the amount does not sum to 100. The one case we may be missing out on here is if someone gives 10s for all of the attributes on a 1-10 scale, but those would get rescaled to 10s anyways.\n",
    "\n",
    "This means that the data type for each of these columns will end up being continuous & in range [0,100].\n",
    "\n",
    "Now, back to the columns.\n",
    "\n",
    "These six features are related to what the participant looks for in the opposite sex:\n",
    "- attr1_1\n",
    "- sinc1_1\n",
    "- intel1_1\n",
    "- fun1_1\n",
    "- amb1_1\n",
    "- shar1_1\n",
    "\n",
    "The next six features are what the participant thinks most of their fellow men/women look for in the opposite sex:\n",
    "- attr4_1\n",
    "- sinc4_1\n",
    "- intel4_1\n",
    "- fun4_1\n",
    "- amb4_1\n",
    "- shar4_1\n",
    "\n",
    "The next six features are what the participant thinks the opposite sex looks for in a date:\n",
    "- attr2_1\n",
    "- sinc2_1\n",
    "- intel2_1\n",
    "- fun2_1\n",
    "- amb2_1\n",
    "- shar2_1\n",
    "\n",
    "The next five features are how the participant rates themselves (discrete & in range [1,10]):\n",
    "- attr3_1\n",
    "- sinc3_1\n",
    "- intel3_1\n",
    "- fun3_1\n",
    "- amb3_1\n",
    "\n",
    "The next five features are how the participant thinks others would rate them (discrete & in range [1,10]):\n",
    "- attr5_1\n",
    "- sinc5_1\n",
    "- intel5_1\n",
    "- fun5_1\n",
    "- amb5_1\n",
    "\n",
    "Moving on to information collected at the dates:\n",
    "- dec (boolean): does the participant want to meet their date partner again\n",
    "\n",
    "Next is how the participant rates their date on the six attributes from above (discrete & in range [1,10]): \n",
    "- attr\n",
    "- sinc\n",
    "- intel\n",
    "- fun\n",
    "- amb\n",
    "- shar\n",
    "\n",
    "And two final features related to the specific date:\n",
    "- like (discrete & in range [1,10]): how much the participant likes their date overall\n",
    "- prob (discrete & in range [1,10]): how probable do you think it is that your partner will want to see you again"
   ],
   "id": "1ca8bfeb926e7bf3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "2f568e1865ce5723"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T03:17:03.563755Z",
     "start_time": "2024-05-20T03:17:03.454930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df_raw[[\n",
    "    'gender'\n",
    "    , 'int_corr'\n",
    "    , 'age_o'\n",
    "    , 'age'\n",
    "    , 'goal'\n",
    "    , 'exphappy'\n",
    "    , 'attr1_1'\n",
    "    , 'sinc1_1'\n",
    "    , 'intel1_1'\n",
    "    , 'fun1_1'\n",
    "    , 'amb1_1'\n",
    "    , 'shar1_1'\n",
    "    , 'attr4_1'\n",
    "    , 'sinc4_1'\n",
    "    , 'intel4_1'\n",
    "    , 'fun4_1'\n",
    "    , 'amb4_1'\n",
    "    , 'shar4_1'\n",
    "    , 'attr2_1'\n",
    "    , 'sinc2_1'\n",
    "    , 'intel2_1'\n",
    "    , 'fun2_1'\n",
    "    , 'amb2_1'\n",
    "    , 'shar2_1'\n",
    "    , 'attr3_1'\n",
    "    , 'sinc3_1'\n",
    "    , 'intel3_1'\n",
    "    , 'fun3_1'\n",
    "    , 'amb3_1'\n",
    "    , 'attr5_1'\n",
    "    , 'sinc5_1'\n",
    "    , 'intel5_1'\n",
    "    , 'fun5_1'\n",
    "    , 'amb5_1'\n",
    "    , 'dec'\n",
    "    , 'attr'\n",
    "    , 'sinc'\n",
    "    , 'intel'\n",
    "    , 'fun'\n",
    "    , 'amb'\n",
    "    , 'shar'\n",
    "    , 'like'\n",
    "    , 'prob'\n",
    "]]\n",
    "\n",
    "df.head()"
   ],
   "id": "3fa49a28ba3b7d92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   gender  int_corr  age_o   age  goal  exphappy  attr1_1  sinc1_1  intel1_1  \\\n",
       "0     0.0      0.14   27.0  21.0   2.0       3.0     15.0     20.0      20.0   \n",
       "1     0.0      0.54   22.0  21.0   2.0       3.0     15.0     20.0      20.0   \n",
       "2     0.0      0.16   22.0  21.0   2.0       3.0     15.0     20.0      20.0   \n",
       "3     0.0      0.61   23.0  21.0   2.0       3.0     15.0     20.0      20.0   \n",
       "4     0.0      0.21   24.0  21.0   2.0       3.0     15.0     20.0      20.0   \n",
       "\n",
       "   fun1_1  ...  amb5_1  dec  attr  sinc  intel  fun  amb  shar  like  prob  \n",
       "0    15.0  ...     NaN  1.0   6.0   9.0    7.0  7.0  6.0   5.0   7.0   6.0  \n",
       "1    15.0  ...     NaN  1.0   7.0   8.0    7.0  8.0  5.0   6.0   7.0   5.0  \n",
       "2    15.0  ...     NaN  1.0   5.0   8.0    9.0  8.0  5.0   7.0   7.0   NaN  \n",
       "3    15.0  ...     NaN  1.0   7.0   6.0    8.0  7.0  6.0   8.0   7.0   6.0  \n",
       "4    15.0  ...     NaN  1.0   5.0   6.0    7.0  7.0  6.0   6.0   6.0   6.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>age_o</th>\n",
       "      <th>age</th>\n",
       "      <th>goal</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>amb5_1</th>\n",
       "      <th>dec</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## EDA",
   "id": "22855a998ca88ec1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Identification\n",
    "\n",
    "I also want to test out a few different classification models. The obvious model for a binary classification problem is logistic regression. I also want to test out support vector machines (SVM), especially for a larger feature space. Finally, I would like to test out a tree-based model, but the specifics for this one will depend on what I find from some of the feature reduction.\n"
   ],
   "id": "c7a59318786d5255"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Building",
   "id": "ad11384b560962b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Training",
   "id": "d79c68610534c8fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results",
   "id": "5782bd27c7603776"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conclusion",
   "id": "86959f6e581f4fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
