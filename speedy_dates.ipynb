{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## To-Do list\n",
    "\n",
    "I am using JetBrains' DataSpell IDE for this project. It is essentially a nice JetBrains IDE experience wrapped around Jupyter notebooks. Normally JetBrains IDEs have built-in support for to-dos, but I cannot get it working for DataSpell. So I will use a separate markdown codeblock here to track outstanding items.\n",
    "\n",
    "### Project Cell\n",
    "\n",
    "- Finish story around why this dataset/study/analysis is important, both generally and personally\n",
    "- Call out issues with the design and what improvements could be made to it. For example, the only matches they look at are for opposite-sex individuals.\n",
    "- Talk about methods used for EDA and analysis. For example, maybe look at some unsupervised learning such as PCA to trim the feature space.\n",
    "- Determine a couple of questions that make sense after reading the paper and test out some models and statistical questions based on those\n",
    "- Make sure to talk about some of the assumptions of the paper. For example, the paper mentions a bunch of social theories related to dating. What happens if we do not follow some of those theories?\n",
    "\n",
    "\n",
    "### Notes from Published Paper\n",
    "\n",
    "- Researchers looked at yes/no decisions separate from matches\n",
    "- Four minute speed dates\n",
    "- Participants were students in graduate and professional schools at Columbia University (selection bias maybe)\n",
    "- Score card\n",
    "    - Yes/No (main variable of interest)\n",
    "        - Decision$_{ij}$ is the decision of subject *i* about person *j*\n",
    "    - Six attributes to rate the other person on\n",
    "        - Attractive\n",
    "        - Sincere\n",
    "        - Intelligent\n",
    "        - Fun\n",
    "        - Ambitious\n",
    "        - Shared interests\n",
    "- Women stayed seated and men rotated\n",
    "- Study primarily looks at differential gender effects\n",
    "    - Male$_i$ indicator variable\n",
    "- Study only looks at attractiveness, intelligence, and ambition. The omitted characteristics had similar weights. \n",
    "    - Rating$_ijc$ is subject *i's* rating on a ten-point scale about *j* on characteristic *c* $\\in$ {Attractiveness, Intelligence, Ambition}\n",
    "    - Observations that have missing values for one of these three characteristics are omitted from the regression\n",
    "    - $\\bar{Rating}_{-ijc}$ is the average rating for a characteristic from everyone who rated person *j* and the $-i$ means that *i* is excluded from this average\n",
    "- There are a few log measures for SAT at undergrad institution, median income in zip code, and population density in zip code\n",
    "- Self$_{ic}$ is subject *i's* rating for themselves on characteristic *c*\n",
    "    - Others$_{ic}$ is how others who rated *i* rated them on *c*\n",
    "- Each participant did a pre-event survey where the researchers gathered some of the non-event data about subjects\n",
    "- Pre-event survey is used to determine ahead of time a few measures SameABC$_{ij}$ to say if the two people had the same ABC attribute\n",
    "- Yeses%_i$ and other related measures relate to how many people *i* said yes to\n",
    "- Table 2a shows descriptive statistics. Maybe include a section in the project that does some summary descriptive statistics to orient ourselves to the data. Also look at table 2b\n",
    "- Page 685 starts to have some conditions and assumptions about men fearing rejection leading to lower desire for more intelligent or more ambitious women. Also asks why there is a difference in fear of rejection between genders. At least the paper is starting to question some of these things.\n",
    "- Some survey results are subjective (ratings) and others are objective (SAT, zip code, etc)\n",
    "    - Objective data is much more sparse if you try to include all three features\n",
    "- In pre-event survey, participants rated their interest in seventeen activities and has SharedInterests features to compare between participants\n",
    "\n",
    "### Preprocessing Cell (not there yet)\n",
    "\n",
    "- Look at categorical features and decide what types of mappings need to happen (numerical to string categories)."
   ],
   "id": "8782b8fff01b706b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T02:43:22.603949Z",
     "start_time": "2024-05-04T02:43:22.037543Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "10b19e6025b8c5d2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data\n",
    "\n",
    "Fisman, R. J., Iyengar, S. S, Kamenica, E. & Simonson, I. (2006). *Gender Differences in Mate Selection: Evidence from a Speed Dating Experiment*. [http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating]. The Quarterly Journal of Economics. https://academiccommons.columbia.edu/doi/10.7916/D8FB585Z\n",
    "\n",
    "Short post and supplemental information about the dataset and the associated experiment: [https://statmodeling.stat.columbia.edu/2008/01/21/the_speeddating_1](https://statmodeling.stat.columbia.edu/2008/01/21/the_speeddating_1). \n",
    "\n",
    "The link for the file share in the formal citation at the start of this cell has both the data in CSV format and a key for understanding the CSV: [http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating](http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating)\n",
    "\n",
    "Data source that I originally found and that led me to the less processed and closer-to-raw source at the Columbia site: [https://www.openml.org/search?type=data&sort=runs&status=active&id=40536](https://www.openml.org/search?type=data&sort=runs&status=active&id=40536)\n",
    "\n",
    "This dataset comes from an experiment by Ray Fisman and Sheena Iyengar of the Columbia Business School and contains data about participants in a speed dating experiment. The most salient target is the `match` column, but the experimental design allows for observation of decisions that are more granular that match or no match, and the associated paper focuses on yes/no decisions by individuals instead of matches that have yes decisions on both sides."
   ],
   "id": "bf0a1369558ebc74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Project\n",
    "\n",
    "Determining what shared features between date participants seems like a perennial question. The more successful relationships out there, the better. On a personal note, I am looking at starting dating again myself, so I am curious about research that can help me to understand the different preferences that I or my date hold and how those may affect a second date. \n",
    "\n",
    "The speed dating setting and the demographics of the study's participants may not generalize well enough to the larger population, but the findings provide a starting point that is backed by empirical evidence.\n",
    "\n",
    "The paper that reports on this data is really useful for determining ways to trim the number of features down."
   ],
   "id": "81b2aeb68c1ecb50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fixing Bad Characters in Source CSV\n",
    "\n",
    "The source CSV from the link above has some characters that got encoded with the Unicode replacement character, the diamond with a question mark in it. You can search for this by using a regex and looking for code `\\uFFFD` or `\\xEF\\xBF\\xBD`. These replacement characters look like the only non-ASCII characters. You can search for these with the character set `[^\\x00-\\x7F]` A visual scan of the bad rows looks like the characters are meant to be 'é'.\n",
    "\n",
    "Sample bad value in the `undergra` field from the source CSV: Ecole Normale Sup�rieure, Paris\n",
    "\n",
    "\n",
    "The following code block calls out to the shell to create a copy of the speed dating CSV and then run `sed` to replace the replacement characters with regular 'e's to keep everything in ASCII. I decided to use shell commands because I had trouble finding a way to read the bad characters in with Python, so I could not get to the step of replacing them in Python. I was able to manually change them with find and replace in Vim, so I modified that for `sed` for the solution below.\n",
    "\n",
    "I ran this on MacOS. You may need to make some tweaks for Windows in particular."
   ],
   "id": "ff276e635ece96ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T02:43:22.915226Z",
     "start_time": "2024-05-04T02:43:22.606978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "! cp ./data/Speed\\ Dating\\ Data.csv ./data/speed_dating_data_fixed.csv\n",
    "! sed -i '' 's/\\xEF\\xBF\\xBD/e/g' ./data/speed_dating_data_fixed.csv  "
   ],
   "id": "38ce16dd610a88d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading\n",
   "id": "f50dd43b59522039"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T02:43:23.183472Z",
     "start_time": "2024-05-04T02:43:22.917545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The low_memory=False param tells pandas to determine column data types by looking at all rows\n",
    "# in each column, resulting in needing to read in the entire CSV before being able to determine\n",
    "# data types. low_memory=True results in chunking when reading in the file, and each chunk can\n",
    "# infer a different data type. I will likely pass in a stricter data type spec later on to keep\n",
    "# chunking but to get explicit data types\n",
    "\n",
    "df_raw = pd.read_csv('./data/speed_dating_data_fixed.csv', low_memory=False)\n",
    "df_raw.head(10)"
   ],
   "id": "fffe6b33320eb605",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave round position  positin1  order  ...  \\\n",
       "0  1.0  1.0     0.0    1       1     1    10        7       NaN      4  ...   \n",
       "1  1.0  1.0     0.0    1       1     1    10        7       NaN      3  ...   \n",
       "2  1.0  1.0     0.0    1       1     1    10        7       NaN     10  ...   \n",
       "3  1.0  1.0     0.0    1       1     1    10        7       NaN      5  ...   \n",
       "4  1.0  1.0     0.0    1       1     1    10        7       NaN      7  ...   \n",
       "5  1.0  1.0     0.0    1       1     1    10        7       NaN      6  ...   \n",
       "6  1.0  1.0     0.0    1       1     1    10        7       NaN      1  ...   \n",
       "7  1.0  1.0     0.0    1       1     1    10        7       NaN      2  ...   \n",
       "8  1.0  1.0     0.0    1       1     1    10        7       NaN      8  ...   \n",
       "9  1.0  1.0     0.0    1       1     1    10        7       NaN      9  ...   \n",
       "\n",
       "   attr3_3  sinc3_3 intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
       "0      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "1      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "2      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "3      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "4      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "5      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "6      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "7      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "8      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "9      5.0      7.0      7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "\n",
       "   fun5_3  amb5_3  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  \n",
       "5     NaN     NaN  \n",
       "6     NaN     NaN  \n",
       "7     NaN     NaN  \n",
       "8     NaN     NaN  \n",
       "9     NaN     NaN  \n",
       "\n",
       "[10 rows x 195 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 195 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pre-Cleaning Exploratory Data Analysis (EDA)\n",
   "id": "231a79e8d517bc51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
